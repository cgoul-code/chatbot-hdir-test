{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa72ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92b811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM generate answer\n",
      "1 text chunks after repacking\n",
      "found node with score: 0.9007370712205328\n",
      "Starting parallel calls for constructing a structures response\n",
      "\n",
      "30.27155727155727\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Oppsummering av svaret\n",
       "\n",
       "## Spørsmålet fra brukeren\n",
       "Hei, jeg vaper daglig og har gjort ganske lenge. Jeg begynner å bli stressa og har lyst til å stoppe, men jeg får det ikke til. Jeg har mener at jeg har fått dårligere hud, munnsår, tjukkere ansikt (men har ikke lagt på meg), blir mer sjesken på mat når jeg ikke har vape. Kan munnsår ha noe med vape å gjøre eller ikke? Er mye jeg lurer på i samme spørsmål\n",
       "\n",
       "## Tittel\n",
       "\"Kan vaping påvirke helsen min?\"\n",
       "\n",
       "## Kort sammendrag av spørsmålet\n",
       "Hei, jeg lurer på om munnsår kan ha noe med vaping å gjøre, siden jeg har vaper daglig, begynner å bli stressa og ønsker å stoppe, men opplever dårligere hud, munnsår, tjukkere ansikt uten å ha lagt på meg, og mer sult på mat når jeg ikke har vape.\n",
       "\n",
       "## Lettlest svar\n",
       "Hei!\n",
       "\n",
       "Jeg forstår at du føler deg stresset og ønsker å slutte å vape. Det er bra at du tenker på helsen din. Når det gjelder munnsår, tjukkere ansikt og sjenanse på mat, kan det være flere faktorer som spiller inn. Vaping kan påvirke huden din, men det er ikke sikkert at det er den eneste årsaken til hudproblemene dine. Munnsår kan også ha ulike årsaker, men det kan være lurt å være oppmerksom på om det kan være en sammenheng med vaping.\n",
       "\n",
       "Når det gjelder å slutte å vape, kan det være utfordrende på grunn av avhengighet. Det er viktig å være motivert og ha en plan for å slutte. Du kan oppleve abstinenssymptomer når du slutter, som stress, sjenanse på mat og andre symptomer du nevnte. Disse symptomene kan være midlertidige og vil avta etter hvert som kroppen tilpasser seg.\n",
       "\n",
       "Det kan være lurt å søke støtte fra helsepersonell eller en rådgiver for å få hjelp til å slutte å vape. De kan gi deg råd og veiledning for å takle abstinenssymptomer og støtte deg gjennom prosessen med å slutte.\n",
       "\n",
       "Husk at det er aldri for sent å ta vare på helsen din og slutte med vaner som ikke er bra for deg. Lykke til, og ikke nøl med å søke hjelp hvis du trenger det!\n",
       "\n",
       "Vennlig hilsen,\n",
       "Din assistent\n",
       "\n",
       "## Referanser\n",
       "- [Kan man få kviser av vaping? — Ung.no](https://www.ung.no/oss/1CZBNuIlYCNLm1OAFy2Uts) (Relevans: 0.90)\n",
       "- [Har sluttet å vape. Har jeg skadet lungene mine? — Ung.no](https://www.ung.no/oss/7cy8QWTOAUDsdYFcrrfuVv) (Relevans: 0.89)\n",
       "- [Tror jeg er avhengig og er lungene ødelagt av vape? — Ung.no](https://www.ung.no/oss/fXPkeBhneNpvW1NHaMybpM) (Relevans: 0.88)\n",
       "- [Jeg vil gjerne slutte med vape, synes nå det er teit at jeg begynte? — Ung.no](https://www.ung.no/oss/MowV7UUn50SgMtSE2C54f4) (Relevans: 0.88)\n",
       "- [Kan man bli sår i halsen og få mer slim av å vape? — Ung.no](https://www.ung.no/oss/xFx6R0VpreHXZthyUnfthX) (Relevans: 0.88)\n",
       "- [Har vapet og prøvd røyk en liten periode, vil jeg få rynker? — Ung.no](https://www.ung.no/oss/2hER7Y3A5Cqjg4Jhw13swI) (Relevans: 0.88)\n",
       "- [Kan det å vape litt være skadelig? — Ung.no](https://www.ung.no/oss/17JoCmSdTn9AdtkKfVrtAu) (Relevans: 0.88)\n",
       "- [Vil lungene mine bli bedre hvis jeg slutter å vape? — Ung.no](https://www.ung.no/oss/q533WEMU35eJVTMbUF5evg) (Relevans: 0.88)\n",
       "- [Hvorfor har jeg blitt kortpustet av vape? — Ung.no](https://www.ung.no/oss/akHdZQICxt8JjivM40lvv1) (Relevans: 0.88)\n",
       "- [Kan jeg fortsatt få helseskader hvis jeg slutter helt å vape nå? — Ung.no](https://www.ung.no/oss/WdwvWKVMBI6e9tAqpSnbHM) (Relevans: 0.88)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re\n",
    "from typing_extensions import  List, Literal\n",
    "import operator\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# LLM og verktøy\n",
    "\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "from llama_index.core import (get_response_synthesizer)\n",
    "\n",
    "\n",
    "from llama_index.core import (StorageContext,  load_index_from_storage)\n",
    "from llama_index.core.base.response.schema import Response\n",
    "from llama_index.core.query_engine import BaseQueryEngine\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "# Import av langchain og langgraph\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Indeksverktøy\n",
    "LLMGPT4omini = AzureChatOpenAI(\n",
    "    model=os.getenv('AZURE_OPENAI_MODEL_GPT4omini'),\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME_GPT4omini'),\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME_GPT4omini'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY_GPT4omini'),\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_AZURE_ENDPOINT_GPT4omini'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSJON_GPT4omini'),\n",
    "    temperature=0.0,\n",
    "    timeout= 120,\n",
    ")\n",
    "\n",
    "def read_index_from_storage(storage):\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=storage)\n",
    "    return load_index_from_storage(storage_context)\n",
    "\n",
    "# Sett Azure OpenAI-legitimasjon\n",
    "\n",
    "llm = LLMGPT4omini\n",
    "\n",
    "chat_text_qa_msgs = [\n",
    "    ChatMessage(\n",
    "        role=MessageRole.SYSTEM,\n",
    "        content=(\n",
    "            \"You are a helpful assistant, and you will be given a user request.\"+\n",
    "            \"\\nYou will respond with empathy\"+\n",
    "            \"\\nYou will answer in language that young people aged 13 to 19 understand\"+\n",
    "            \"\\nSome rules to follow:\"+\n",
    "            \"\\n- Always answer the request using the given context information and not prior knowledge\"+\n",
    "            \"\\n- Provide a detailed explanation, but avoid repetitions.\"+\n",
    "            \"\\n- Always answer in norwegian\"\n",
    "        ),\n",
    "    )\n",
    "    ,\n",
    "    ChatMessage(\n",
    "        role=MessageRole.USER,\n",
    "        content=(\n",
    "            \"Context information is below.\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"{context_str}\\n\"\n",
    "            \"---------------------\\n\"\n",
    "            \"Query: {query_str}\\n\"\n",
    "            \"Answer: \"\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "text_qa_template =  ChatPromptTemplate(chat_text_qa_msgs)\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode= \"tree_summarize\",\n",
    "    text_qa_template = text_qa_template,\n",
    "    summary_template= text_qa_template, #definitly in use for response_mode = tree_summarize\n",
    "    structured_answer_filtering=True, \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# intialize the LLM engine:\n",
    "storage = './blobstorage/chatbot/ungnospmtobakk'\n",
    "index = read_index_from_storage(storage)\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_cutoff=0.7,\n",
    "    similarity_top_k=10,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "class Reference(TypedDict):\n",
    "    name: str\n",
    "    url: str\n",
    "    relevance_index: float    \n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    grade: Literal [\"readable\", \"not readable\"] = Field(description=\"Decide if an answer is readable or not.\")\n",
    "    feedback: str = Field(description = \"Answer is not readable, provide feedback on how to improve it\")\n",
    "\n",
    "    \n",
    "# Augment the LLM with schema for structured output\n",
    "evaluator = llm.with_structured_output(Feedback)\n",
    "    \n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    query_engine: BaseQueryEngine\n",
    "    similarity_cutoff:float\n",
    "    query: str\n",
    "    query_short_version: str\n",
    "    query_summary: str\n",
    "    response: Response\n",
    "    response_validity: Literal[\"valid\", \"not valid\"]\n",
    "    nodes_with_relevancy : List[NodeWithScore]\n",
    "    answer: str\n",
    "    structured_answer: str\n",
    "    lix_score: float\n",
    "    lix_category: str\n",
    "    references: List[Reference]\n",
    "    feedback: str  # <-- legg til denne\n",
    "    readable_or_not: Literal[\"readable\", \"not readable\"]  # legg gjerne til denne også\n",
    "    \n",
    "# Function to categorize LIX score\n",
    "def categorize_lix(lix):\n",
    "    if lix < 25:\n",
    "        return \"Svært lettlest (for barn)\"\n",
    "    elif 25 <= lix < 35:\n",
    "        return \"Lettlest (enkel litteratur, aviser)\"\n",
    "    elif 35 <= lix < 45:\n",
    "        return \"Middels vanskelig (standard aviser, generell sakprosa)\"\n",
    "    elif 45 <= lix < 55:\n",
    "        return \"Vanskelig (akademiske tekster, offisielle dokumenter)\"\n",
    "    else:\n",
    "        return \"Svært vanskelig (vitenskapelig litteratur)\"\n",
    "    \n",
    "# Nodes\n",
    "def llm_call_short_version_generator(state: State):\n",
    "    \"\"\"LLM generates a short version for the query\"\"\"\n",
    "    try: \n",
    "        msg = llm.invoke(\n",
    "                f\"Give a title in norwegian to the query, ensuring that the 'I' form is preserved: {state['query']}, use only one short sentence\"\n",
    "            )\n",
    "        return {\"query_short_version\": msg.content}\n",
    "    except Exception as e:\n",
    "        return {\"query_short_version\": f\"Error: {str(e)}\"}\n",
    "    \n",
    "def llm_call_summary_generator(state: State):\n",
    "    \"\"\"LLM generates a summary for the query\"\"\"\n",
    "    try:\n",
    "        msg = llm.invoke(\n",
    "                f\"Please provide a summary of the user's question in norwegian, ensuring that the 'I' form is preserved : {state['query']}, use only one sentence\"\n",
    "            )\n",
    "        return {\"query_summary\": msg.content}\n",
    "    except Exception as e:\n",
    "        return {\"query_summary\": f\"Error: {str(e)}\"}\n",
    "\n",
    "def calculate_readability_index(state: State):\n",
    "\n",
    "    text = state[\"answer\"]\n",
    "    \n",
    "    if text :\n",
    "        # Count words\n",
    "        words = text.split()\n",
    "        num_words = len(words)\n",
    "\n",
    "        # Count sentences (assuming sentences end with '.', '!', or '?')\n",
    "        num_sentences = len(re.split(r'[.!?]', text)) - 1  # Remove trailing empty splits\n",
    "\n",
    "        # Count long words (more than 6 letters)\n",
    "        num_long_words = sum(1 for word in words if len(re.sub(r'[^a-zA-Z]', '', word)) > 6)\n",
    "\n",
    "        # Calculate LIX\n",
    "        lix_score = (num_words / num_sentences) + (num_long_words / num_words) * 100\n",
    "        \n",
    "        # Get LIX category\n",
    "        lix_category = categorize_lix(lix_score)\n",
    "        print(f'\\n{lix_score}')\n",
    "        state['lix_score'] = lix_score\n",
    "        state['lix_category'] = lix_category\n",
    "\n",
    "        \n",
    "    return \n",
    "\n",
    "def llm_call_answer(state: State):\n",
    "    \"\"\"LLM generate answer\"\"\"\n",
    "    print('LLM generate answer')\n",
    "    try:\n",
    "        response_obj = query_engine.query(state['query'])  \n",
    "        # Write the  answer to the state\n",
    "        return {\"answer\":  response_obj.response, \"response\": response_obj}\n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"Error: {str(e)}\"}\n",
    "\n",
    "def llm_make_answer_more_readable(state: State):\n",
    "    \"\"\"LLM make the answer more readable\"\"\"\n",
    "    print(f'LLM make the answer more readable')\n",
    "    try: \n",
    "        msg = llm.invoke(f\"This is the answer to improve {state['answer']}, {state['feedback']}\")\n",
    "        return {\"answer\":  msg.content}\n",
    "    except Exception as e:\n",
    "        return {\"answer\": f\"Error: {str(e)}\"}\n",
    "\n",
    "def response_relevancy_evaluator(state: State):\n",
    "    \"\"\"Test the nodes from the response for relevancy\"\"\"\n",
    "    if state[\"response\"] is None:\n",
    "        print (\"failed to get the response\")\n",
    "        return {\"response_validity\": \"not valid\"}\n",
    "    else:\n",
    "        return {\"response_validity\": \"valid\"}\n",
    "    \n",
    "def references_generator(state: State):\n",
    "    references : List[Reference] = []\n",
    "    response = state[\"response\"]\n",
    "    similarity_cutoff = state[\"similarity_cutoff\"]\n",
    "    \n",
    "    # Filter out nodes with score=None\n",
    "    nodes_with_scores = [node for node in response.source_nodes if node.score is not None]\n",
    "\n",
    "    for node in nodes_with_scores:\n",
    "        if node.score >= similarity_cutoff:\n",
    "            metadata = node.metadata\n",
    "            #print(f'Metadata: {metadata}')\n",
    "            text = node.text\n",
    "            url = metadata.get('url', 'Ingen URL')\n",
    "            title = metadata.get('title', 'Ingen tittel').lstrip()\n",
    "            reference: Reference = {\n",
    "                \"name\" : title,\n",
    "                \"url\" : url,\n",
    "                \"relevance_index\" : node.score\n",
    "            }\n",
    "            references.append(reference)\n",
    "        \n",
    "    return( {\"references\": references} )\n",
    "    \n",
    "\n",
    "def readability_evaluator(state: State):\n",
    "    \"\"\"Evaluates the readability of the answer\"\"\"\n",
    "    \n",
    "    calculate_readability_index(state)\n",
    "\n",
    "    if state[\"lix_score\"] > 35:\n",
    "        return {\n",
    "            \"readable_or_not\": \"not readable\",\n",
    "            \"feedback\": \"Make this text more readable by using shorter sentences, fewer words, and simpler language.\"\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"readable_or_not\": \"readable\",\n",
    "            \"feedback\": \"No need for improvements\"\n",
    "        }\n",
    "\n",
    "# Conditional edge function to route back to call for more readable answer\n",
    "def route_answer(state: State):\n",
    "    \"\"\"Route back to answer generator or end based upon feedback from the evaluator\"\"\"\n",
    "\n",
    "    if state[\"readable_or_not\"] == \"readable\":\n",
    "        return \"Accepted\"\n",
    "    elif state[\"readable_or_not\"] == \"not readable\":\n",
    "        return \"Rejected + Feedback\"\n",
    "    \n",
    "# Conditional edge function to route to construction of a structured answer based upon a result from the evaluator\n",
    "def validate_response(state: State):\n",
    "    \"\"\"Route to answer generator or end based upon feedback from the evaluator\"\"\"\n",
    "    \n",
    "    response = state[\"response\"]\n",
    "    \n",
    "    # Filter out nodes with score=None\n",
    "    nodes_with_scores = [node for node in response.source_nodes if node.score is not None]\n",
    "    \n",
    "    if nodes_with_scores:\n",
    "        for node in nodes_with_scores:\n",
    "            if node.score >= state[\"similarity_cutoff\"]:\n",
    "                print(f'found node with score: {node.score}')\n",
    "                return \"Accepted\"\n",
    "\n",
    "    return \"Rejected + Feedback\"\n",
    "    \n",
    "    \n",
    "def response_builder_node(state: State) -> State:\n",
    "    print(\"Starting parallel calls for constructing a structures response\")\n",
    "    return state  # just pass along\n",
    "    \n",
    "def aggregator(state: State):\n",
    "    \"\"\"Combine answer with structured info into Markdown format\"\"\"\n",
    "    \n",
    "    combined = f\"# Oppsummering av svaret\\n\\n\"\n",
    "    \n",
    "    combined += f\"## Spørsmålet fra brukeren\\n\"\n",
    "    combined += f\"{state['query']}\\n\\n\"\n",
    "    \n",
    "    combined += f\"## Tittel\\n\"\n",
    "    combined += f\"{state['query_short_version']}\\n\\n\"\n",
    "    \n",
    "    combined += f\"## Kort sammendrag av spørsmålet\\n\"\n",
    "    combined += f\"{state['query_summary']}\\n\\n\"\n",
    "    \n",
    "    combined += f\"## Lettlest svar\\n\"\n",
    "    combined += f\"{state['answer']}\\n\\n\"\n",
    "    \n",
    "    # Optional: include references if you have them\n",
    "    if \"references\" in state and state[\"references\"]:\n",
    "        combined += \"## Referanser\\n\"\n",
    "        for ref in state[\"references\"]:\n",
    "            combined += f\"- [{ref['name']}]({ref['url']}) (Relevans: {ref['relevance_index']:.2f})\\n\"\n",
    "    \n",
    "    return {\"structured_answer\": combined}\n",
    "    \n",
    "# Build workflow\n",
    "optimizer_builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes\n",
    "optimizer_builder.add_node(\"llm_call_short_version_generator\", llm_call_short_version_generator)\n",
    "optimizer_builder.add_node(\"response_relevancy_evaluator\", response_relevancy_evaluator)\n",
    "optimizer_builder.add_node(\"llm_call_summary_generator\", llm_call_summary_generator)\n",
    "optimizer_builder.add_node(\"llm_call_answer\", llm_call_answer)\n",
    "optimizer_builder.add_node(\"readability_evaluator\", readability_evaluator)\n",
    "optimizer_builder.add_node(\"llm_make_answer_more_readable\", llm_make_answer_more_readable)\n",
    "optimizer_builder.add_node(\"aggregator\", aggregator)\n",
    "optimizer_builder.add_node(\"response_builder_node\", response_builder_node)\n",
    "optimizer_builder.add_node(\"references_generator\", references_generator)\n",
    "\n",
    "# # Add edges to connect nodes\n",
    "optimizer_builder.add_edge(START, \"llm_call_answer\")\n",
    "optimizer_builder.add_edge(\"llm_call_answer\", \"response_relevancy_evaluator\")\n",
    "\n",
    "optimizer_builder.add_edge(\"response_builder_node\", \"readability_evaluator\")\n",
    "optimizer_builder.add_edge(\"response_builder_node\", \"llm_call_short_version_generator\")\n",
    "optimizer_builder.add_edge(\"response_builder_node\", \"llm_call_summary_generator\")\n",
    "optimizer_builder.add_edge(\"response_builder_node\", \"references_generator\")\n",
    "\n",
    "\n",
    "optimizer_builder.add_edge(\"llm_make_answer_more_readable\", \"readability_evaluator\")\n",
    "\n",
    "optimizer_builder.add_edge(\"llm_call_short_version_generator\", \"aggregator\")\n",
    "optimizer_builder.add_edge(\"llm_call_summary_generator\", \"aggregator\")\n",
    "optimizer_builder.add_edge(\"references_generator\", \"aggregator\")\n",
    "optimizer_builder.add_edge(\"aggregator\", END)\n",
    "\n",
    "optimizer_builder.add_conditional_edges(\n",
    "    \"response_relevancy_evaluator\",\n",
    "    validate_response,\n",
    "    {  # Name returned by route_answer : Name of next node to visit\n",
    "        \"Accepted\": \"response_builder_node\",\n",
    "        \"Rejected + Feedback\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "optimizer_builder.add_conditional_edges(\n",
    "    \"readability_evaluator\",\n",
    "    route_answer,\n",
    "    {  # Name returned by route_answer : Name of next node to visit\n",
    "        \"Accepted\": \"aggregator\",\n",
    "        \"Rejected + Feedback\": \"llm_make_answer_more_readable\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# Compile the workflow\n",
    "optimizer_workflow = optimizer_builder.compile()\n",
    "\n",
    "#from graph_utils import save_mermaid_diagram\n",
    "from graph_utils import save_mermaid_diagram\n",
    "#save_mermaid_diagram(optimizer_workflow.get_graph())\n",
    "\n",
    "# Invoke\n",
    "state = optimizer_workflow.invoke({\"query_engine\": query_engine,\n",
    "                                   \"similarity_cutoff\": 0.7, \n",
    "                                   \"query\": \"Hei, jeg vaper daglig og har gjort ganske lenge. Jeg begynner å bli stressa og har lyst til å stoppe, men jeg får det ikke til. Jeg har mener at jeg har fått dårligere hud, munnsår, tjukkere ansikt (men har ikke lagt på meg), blir mer sjesken på mat når jeg ikke har vape. Kan munnsår ha noe med vape å gjøre eller ikke? Er mye jeg lurer på i samme spørsmål\"})\n",
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(state[\"structured_answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
