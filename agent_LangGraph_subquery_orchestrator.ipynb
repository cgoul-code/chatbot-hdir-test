{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa72ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "llm_call invoked: Worker answer a subquery\n",
      "\n",
      "llm_call invoked: Worker answer a subquery\n",
      "\n",
      "llm_call invoked: Worker answer a subquery\n",
      "1 text chunks after repacking\n",
      "1 text chunks after repacking\n",
      "\u001b[33mQuery: \u001b[34mNår sank Titanic?\u001b[0m\u001b[33mAnswer: \u001b[34mDette spørsmålet omhandler ikke informasjonen som er gitt i konteksten.\n",
      "1 text chunks after repacking\n",
      "\u001b[33mQuery: \u001b[34mEr snus skadelig for min helse?\u001b[0m\u001b[33mAnswer: \u001b[34mJa, snus er skadelig for helsen din. Snus inneholder helseskadelige stoffer og kan føre til ulike helseproblemer som kreft, hjerteproblemer, diabetes og påvirke utviklingen av hjernen. Det er spesielt farlig for gravide å bruke snus, da det kan påvirke fosteret negativt. Det anbefales å unngå snus for å opprettholde god helse.\n",
      "\u001b[33mQuery: \u001b[34mKan du gi meg tips på hvordan slutte å røyke?\u001b[0m\u001b[33mAnswer: \u001b[34mFor å slutte å røyke kan du følge disse tipsene:\n",
      "\n",
      "1. Finn noe som motiverer deg til å slutte. Skriv ned alle gode grunner for å slutte og ha de synlige hver dag.\n",
      "2. Sett en sluttdato og ta hensyn til abstinenser i tiden etter nikotinslutt.\n",
      "3. Finn støtte i andre, del med andre at du har bestemt deg for å slutte.\n",
      "4. Bruk Slutta-appen for daglige motivasjonsmeldinger og tips.\n",
      "5. Belønn deg selv når du når delmål, for eksempel med en hyggelig aktivitet eller en liten premie.\n",
      "\n",
      "Lykke til med røykeslutt!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Tips for å slutte å røyke\n",
       "\n",
       "For å slutte å røyke kan du følge disse tipsene:\n",
       "\n",
       "1. **Motivasjon**: Finn noe som motiverer deg til å slutte. Skriv ned alle gode grunner for å slutte og ha dem synlige hver dag.\n",
       "2. **Sluttdato**: Sett en sluttdato og vær forberedt på abstinenser i tiden etter nikotinslutt.\n",
       "3. **Støtte**: Finn støtte i andre. Del med venner og familie at du har bestemt deg for å slutte.\n",
       "4. **Verktøy**: Bruk Slutta-appen for daglige motivasjonsmeldinger og tips.\n",
       "5. **Belønning**: Belønn deg selv når du når delmål, for eksempel med en hyggelig aktivitet eller en liten premie.\n",
       "\n",
       "Lykke til med røykeslutt!\n",
       "\n",
       "---\n",
       "\n",
       "## Er snus skadelig for helsen?\n",
       "\n",
       "Ja, snus er skadelig for helsen din. Snus inneholder helseskadelige stoffer og kan føre til ulike helseproblemer som kreft, hjerteproblemer, diabetes, og påvirke utviklingen av hjernen. Det er spesielt farlig for gravide å bruke snus, da det kan påvirke fosteret negativt. Det anbefales å unngå snus for å opprettholde god helse."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, getpass\n",
    "from typing_extensions import Annotated, List\n",
    "import operator\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# LLM og verktøy\n",
    "from llama_index.agent.openai import OpenAIAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import (get_response_synthesizer)\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import (VectorStoreIndex, StorageContext,  load_index_from_storage)\n",
    "\n",
    "# Import av langchain og langgraph\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.constants import Send\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Indeksverktøy\n",
    "LLMGPT4omini = AzureChatOpenAI(\n",
    "    model=os.getenv('AZURE_OPENAI_MODEL_GPT4omini'),\n",
    "    deployment_name=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME_GPT4omini'),\n",
    "    azure_deployment=os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME_GPT4omini'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY_GPT4omini'),\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_AZURE_ENDPOINT_GPT4omini'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSJON_GPT4omini'),\n",
    "    temperature=0.0,\n",
    "    timeout= 120,\n",
    ")\n",
    "\n",
    "def read_index_from_storage(storage):\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=storage)\n",
    "    return load_index_from_storage(storage_context)\n",
    "\n",
    "# Sett Azure OpenAI-legitimasjon\n",
    "\n",
    "llm = LLMGPT4omini\n",
    "\n",
    "\n",
    "# Schema for structured output to use in planning\n",
    "class SubQuery(BaseModel):\n",
    "    subquery: str = Field(\n",
    "        description=\"The subquery\",\n",
    "    )\n",
    "    answer: str = Field(\n",
    "        description=\"Answer to the subquery\",\n",
    "    )\n",
    "\n",
    "\n",
    "class SubQueries(BaseModel):\n",
    "    subqueries: List[SubQuery] = Field(\n",
    "        description=\"Sections of the structured answer.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "planner = llm.with_structured_output(SubQueries)\n",
    "\n",
    "\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    query: str  # Report topic\n",
    "    subqueries: list[SubQuery]  # List of subqueries\n",
    "    completed_answers: Annotated[\n",
    "        list, operator.add\n",
    "    ]  # All workers write to this key in parallel\n",
    "    final_answer: str  # Final report\n",
    "    \n",
    "# Worker state\n",
    "class WorkerState(TypedDict):\n",
    "    subquery: SubQuery\n",
    "    completed_answers: Annotated[list, operator.add]\n",
    "    \n",
    "# some global variables\n",
    "chat_text_qa_msgs = [\n",
    "        ChatMessage(\n",
    "            role=MessageRole.SYSTEM,\n",
    "            content=( \n",
    "                \"You are a helpful assistant, and you will be given a user request.\"\n",
    "                \"Some rules to follow:\"\n",
    "                \"- Always answer the request using the given context information and not prior knowledge\"\n",
    "                \"- Always answer in norwegian\"\n",
    "                \"- Always answer using the format: '\\033[33mAnswer: \\033[34m<answer>\\033[0m'\"\n",
    "\n",
    "            ),\n",
    "        )\n",
    "        ,\n",
    "        ChatMessage(\n",
    "            role=MessageRole.USER,\n",
    "            content=(\n",
    "                \"Context information is below.\\n\"\n",
    "                \"---------------------\\n\"\n",
    "                \"{context_str}\\n\"\n",
    "                \"---------------------\\n\"\n",
    "                \"Query: {query_str}\\n\"\n",
    "                \"Answer: \"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "text_qa_template =  ChatPromptTemplate(chat_text_qa_msgs)\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode= \"tree_summarize\",\n",
    "    text_qa_template = text_qa_template,\n",
    "    summary_template= text_qa_template, #definitly in use for response_mode = tree_summarize\n",
    "    structured_answer_filtering=True, \n",
    "    verbose=True,\n",
    ")\n",
    "text_splitter = SentenceSplitter.from_defaults(chunk_size=1024, chunk_overlap=75)\n",
    "\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def orchestrator(state: State):\n",
    "    \"\"\"Orchestrator that generates a plan for solving the question\"\"\"\n",
    "    # Generate queries\n",
    "    report_queries = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Refrase the user query generating a subquery in norwegian. If the user query har several queries, generate several subqueries. Do not answer the subqueries\"),\n",
    "            HumanMessage(content=f\"Here is query from a user: {state['query']}\"),\n",
    "        ]\n",
    "    )\n",
    "    return {\"subqueries\": report_queries.subqueries}\n",
    "\n",
    "def llm_call(state: State):\n",
    "    \"\"\"Worker answer a subquery\"\"\"\n",
    "    storage = './blobstorage/chatbot/ungnotobakk'\n",
    "    if not state.get(\"index_tobakk\"):\n",
    "        state[\"index_tobakk\"] = read_index_from_storage(storage)\n",
    "    else:\n",
    "        print(f'Index for tobakk already loaded from {storage}')\n",
    "\n",
    "    query_engine = state[\"index_tobakk\"].as_query_engine(\n",
    "        similarity_cutoff=0.7, \n",
    "        similarity_top_k=10,\n",
    "        response_synthesizer=response_synthesizer\n",
    "    )\n",
    "\n",
    "    response_obj = query_engine.query(state['subquery'].subquery)\n",
    "    state['subquery'].answer = response_obj.response\n",
    "    \n",
    "    s = \"\\033[33mQuery: \\033[34m\" + state['subquery'].subquery + \"\\033[0m\" + response_obj.response\n",
    "    print(s)\n",
    "    \n",
    "    # Write the updated answer to completed sections\n",
    "    return {\"completed_answers\": [state['subquery'].subquery + \"\\n\" + response_obj.response]}\n",
    "    \n",
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize full answer from answers from the subqueries\"\"\"\n",
    "\n",
    "    # List of completed sections\n",
    "    completed_answers = state[\"completed_answers\"]\n",
    "\n",
    "    # Format completed section to str to use as context for final sections\n",
    "    completed_report_answers = \"\\n\\n---\\n\\n\".join(completed_answers)\n",
    "    \n",
    "    aggregated_answer = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"from this list of answers, reorganize a final answer. Use markdown formatting.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"Here is the list of answers: {completed_report_answers}\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    #print(aggregated_answer.content)\n",
    "\n",
    "    return {\"final_answer\": aggregated_answer.content}\n",
    "\n",
    "\n",
    "\n",
    "# Conditional edge function to create llm_call workers that each write a section of the report\n",
    "def assign_workers(state: State):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "\n",
    "    # Kick off section writing in parallel via Send() API\n",
    "    return [Send(\"llm_call\", {\"subquery\": s}) for s in state[\"subqueries\"]]\n",
    "\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes\n",
    "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
    "orchestrator_worker_builder.add_node(\"llm_call\", llm_call)\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "orchestrator_worker_builder.add_edge(START, \"orchestrator\")\n",
    "orchestrator_worker_builder.add_conditional_edges(\n",
    "    \"orchestrator\", assign_workers, [\"llm_call\"]\n",
    ")\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\")\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "orchestrator_worker = orchestrator_worker_builder.compile()\n",
    "\n",
    "\n",
    "\n",
    "from graph_utils import save_mermaid_diagram\n",
    "save_mermaid_diagram(orchestrator_worker.get_graph())\n",
    "# Show the workflow\n",
    "#display(Image(router_workflow.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "state = orchestrator_worker.invoke({\"query\": \"Kan du gi meg tips på hvordan slutteå røyke? Når sank titanic? Er snus skadelig for min helse?\"})\n",
    "\n",
    "from IPython.display import Markdown\n",
    "Markdown(state[\"final_answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
